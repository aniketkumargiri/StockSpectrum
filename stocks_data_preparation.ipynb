{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"text_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mainstream media has done an amazing job at b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tesla delivery estimates are at around 364k fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 even if i include 630m unvested rsus as of 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hahaha why are you still trying to stop tesla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop trying to kill kids you sad deranged old...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0   mainstream media has done an amazing job at b...\n",
       "1  tesla delivery estimates are at around 364k fr...\n",
       "2  3 even if i include 630m unvested rsus as of 6...\n",
       "3   hahaha why are you still trying to stop tesla...\n",
       "4   stop trying to kill kids you sad deranged old..."
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81196"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81196, 1)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text'], dtype='object')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81196 entries, 0 to 81195\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    81196 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 634.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>64860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>$TSLA will triple in 2022 ðŸš€ðŸŒ•</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text\n",
       "count                          81196\n",
       "unique                         64860\n",
       "top     $TSLA will triple in 2022 ðŸš€ðŸŒ•\n",
       "freq                              25"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16336"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    64860\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@news #trend, Mainstream media has done an ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla delivery estimates are at around 364k fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/ Even if I include 63.0M unvested RSUs as of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@RealDanODowd @WholeMarsBlog @Tesla Hahaha why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RealDanODowd @Tesla Stop trying to kill kids,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81179</th>\n",
       "      <td>#SBIN @ CRUCIAL ZONE FOR EITHER SIDE https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81182</th>\n",
       "      <td>Some of my #StocksToTrade picks blasted during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81185</th>\n",
       "      <td>#SBIN - SBI buy is possible - TradingView - ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81186</th>\n",
       "      <td>@IndiaPostOffice @cpmgdelhi very important doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81190</th>\n",
       "      <td>*Muharat pick 6*\\nBuy SBI at current market pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64860 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      @news #trend, Mainstream media has done an ama...\n",
       "1      Tesla delivery estimates are at around 364k fr...\n",
       "2      3/ Even if I include 63.0M unvested RSUs as of...\n",
       "3      @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...\n",
       "4      @RealDanODowd @Tesla Stop trying to kill kids,...\n",
       "...                                                  ...\n",
       "81179  #SBIN @ CRUCIAL ZONE FOR EITHER SIDE https://t...\n",
       "81182  Some of my #StocksToTrade picks blasted during...\n",
       "81185  #SBIN - SBI buy is possible - TradingView - ht...\n",
       "81186  @IndiaPostOffice @cpmgdelhi very important doc...\n",
       "81190  *Muharat pick 6*\\nBuy SBI at current market pr...\n",
       "\n",
       "[64860 rows x 1 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contractions expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contractions_dict = {\n",
    "#     \"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "#     \"aren't\": \"are not / am not\",\n",
    "#     \"can't\": \"cannot\",\n",
    "#     \"can't've\": \"cannot have\",\n",
    "#     \"'cause\": \"because\",\n",
    "#     \"could've\": \"could have\",\n",
    "#     \"couldn't\": \"could not\",\n",
    "#     \"couldn't've\": \"could not have\",\n",
    "#     \"didn't\": \"did not\",\n",
    "#     \"doesn't\": \"does not\",\n",
    "#     \"don't\": \"do not\",\n",
    "#     \"hadn't\": \"had not\",\n",
    "#     \"hadn't've\": \"had not have\",\n",
    "#     \"hasn't\": \"has not\",\n",
    "#     \"haven't\": \"have not\",\n",
    "#     \"he'd\": \"he had / he would\",\n",
    "#     \"he'd've\": \"he would have\",\n",
    "#     \"he'll\": \"he shall / he will\",\n",
    "#     \"he'll've\": \"he shall have / he will have\",\n",
    "#     \"he's\": \"he has / he is\",\n",
    "#     \"how'd\": \"how did\",\n",
    "#     \"how'd'y\": \"how do you\",\n",
    "#     \"how'll\": \"how will\",\n",
    "#     \"how's\": \"how has / how is / how does\",\n",
    "#     \"I'd\": \"I had / I would\",\n",
    "#     \"I'd've\": \"I would have\",\n",
    "#     \"I'll\": \"I shall / I will\",\n",
    "#     \"I'll've\": \"I shall have / I will have\",\n",
    "#     \"I'm\": \"I am\",\n",
    "#     \"I've\": \"I have\",\n",
    "#     \"isn't\": \"is not\",\n",
    "#     \"it'd\": \"it had / it would\",\n",
    "#     \"it'd've\": \"it would have\",\n",
    "#     \"it'll\": \"it shall / it will\",\n",
    "#     \"it'll've\": \"it shall have / it will have\",\n",
    "#     \"it's\": \"it has / it is\",\n",
    "#     \"let's\": \"let us\",\n",
    "#     \"ma'am\": \"madam\",\n",
    "#     \"mayn't\": \"may not\",\n",
    "#     \"might've\": \"might have\",\n",
    "#     \"mightn't\": \"might not\",\n",
    "#     \"mightn't've\": \"might not have\",\n",
    "#     \"must've\": \"must have\",\n",
    "#     \"mustn't\": \"must not\",\n",
    "#     \"mustn't've\": \"must not have\",\n",
    "#     \"needn't\": \"need not\",\n",
    "#     \"needn't've\": \"need not have\",\n",
    "#     \"o'clock\": \"of the clock\",\n",
    "#     \"oughtn't\": \"ought not\",\n",
    "#     \"oughtn't've\": \"ought not have\",\n",
    "#     \"shan't\": \"shall not\",\n",
    "#     \"sha'n't\": \"shall not\",\n",
    "#     \"shan't've\": \"shall not have\",\n",
    "#     \"she'd\": \"she had / she would\",\n",
    "#     \"she'd've\": \"she would have\",\n",
    "#     \"she'll\": \"she shall / she will\",\n",
    "#     \"she'll've\": \"she shall have / she will have\",\n",
    "#     \"she's\": \"she has / she is\",\n",
    "#     \"should've\": \"should have\",\n",
    "#     \"shouldn't\": \"should not\",\n",
    "#     \"shouldn't've\": \"should not have\",\n",
    "#     \"so've\": \"so have\",\n",
    "#     \"so's\": \"so as / so is\",\n",
    "#     \"that'd\": \"that would / that had\",\n",
    "#     \"that'd've\": \"that would have\",\n",
    "#     \"that's\": \"that has / that is\",\n",
    "#     \"there'd\": \"there had / there would\",\n",
    "#     \"there'd've\": \"there would have\",\n",
    "#     \"there's\": \"there has / there is\",\n",
    "#     \"they'd\": \"they had / they would\",\n",
    "#     \"they'd've\": \"they would have\",\n",
    "#     \"they'll\": \"they shall / they will\",\n",
    "#     \"they'll've\": \"they shall have / they will have\",\n",
    "#     \"they're\": \"they are\",\n",
    "#     \"they've\": \"they have\",\n",
    "#     \"to've\": \"to have\",\n",
    "#     \"wasn't\": \"was not\",\n",
    "#     \"we'd\": \"we had / we would\",\n",
    "#     \"we'd've\": \"we would have\",\n",
    "#     \"we'll\": \"we will\",\n",
    "#     \"we'll've\": \"we will have\",\n",
    "#     \"we're\": \"we are\",\n",
    "#     \"we've\": \"we have\",\n",
    "#     \"weren't\": \"were not\",\n",
    "#     \"what'll\": \"what shall / what will\",\n",
    "#     \"what'll've\": \"what shall have / what will have\",\n",
    "#     \"what're\": \"what are\",\n",
    "#     \"what's\": \"what has / what is\",\n",
    "#     \"what've\": \"what have\",\n",
    "#     \"when's\": \"when has / when is\",\n",
    "#     \"when've\": \"when have\",\n",
    "#     \"where'd\": \"where did\",\n",
    "#     \"where's\": \"where has / where is\",\n",
    "#     \"where've\": \"where have\",\n",
    "#     \"who'll\": \"who shall / who will\",\n",
    "#     \"who'll've\": \"who shall have / who will have\",\n",
    "#     \"who's\": \"who has / who is\",\n",
    "#     \"who've\": \"who have\",\n",
    "#     \"why's\": \"why has / why is\",\n",
    "#     \"why've\": \"why have\",\n",
    "#     \"will've\": \"will have\",\n",
    "#     \"won't\": \"will not\",\n",
    "#     \"won't've\": \"will not have\",\n",
    "#     \"would've\": \"would have\",\n",
    "#     \"wouldn't\": \"would not\",\n",
    "#     \"wouldn't've\": \"would not have\",\n",
    "#     \"y'all\": \"you all\",\n",
    "#     \"y'all'd\": \"you all would\",\n",
    "#     \"y'all'd've\": \"you all would have\",\n",
    "#     \"y'all're\": \"you all are\",\n",
    "#     \"y'all've\": \"you all have\",\n",
    "#     \"you'd\": \"you had / you would\",\n",
    "#     \"you'd've\": \"you would have\",\n",
    "#     \"you'll\": \"you shall / you will\",\n",
    "#     \"you'll've\": \"you shall have / you will have\",\n",
    "#     \"you're\": \"you are\",\n",
    "#     \"you've\": \"you have\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply contractions fix to each text\n",
    "def fix_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "# Applying the function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(fix_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC_ADDRESS_REGEX',\n",
       " 'CURRENCY_REGEX',\n",
       " 'CURRENCY_SYMB_REGEX',\n",
       " 'Counter',\n",
       " 'DATE_REGEX',\n",
       " 'EMAIL_REGEX',\n",
       " 'EMOJI_REGEX',\n",
       " 'HASTAG_REGEX',\n",
       " 'MASTERCard_REGEX',\n",
       " 'MD5_SHA_REGEX',\n",
       " 'MOST_COMMON_PUNCT_REGEX',\n",
       " 'NUMBERS_REGEX',\n",
       " 'PHONE_REGEX',\n",
       " 'PoBOX_REGEX',\n",
       " 'SPECIAL_CHARACTERS_REGEX',\n",
       " 'STOPWORDS',\n",
       " 'STOPWORDS_de',\n",
       " 'STOPWORDS_en',\n",
       " 'STOPWORDS_es',\n",
       " 'STOPWORDS_fr',\n",
       " 'STOPWORDS_ru',\n",
       " 'STOPWORDS_yo',\n",
       " 'STREET_ADDRESS_REGEX',\n",
       " 'TextFrame',\n",
       " 'URL_PATTERN',\n",
       " 'USER_HANDLES_REGEX',\n",
       " 'VISACard_REGEX',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__generate_text',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__numbers_dict',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_lex_richness_herdan',\n",
       " '_lex_richness_maas_ttr',\n",
       " 'clean_text',\n",
       " 'defaultdict',\n",
       " 'digit2words',\n",
       " 'extract_btc_address',\n",
       " 'extract_currencies',\n",
       " 'extract_currency_symbols',\n",
       " 'extract_dates',\n",
       " 'extract_emails',\n",
       " 'extract_emojis',\n",
       " 'extract_hashtags',\n",
       " 'extract_html_tags',\n",
       " 'extract_mastercard_addr',\n",
       " 'extract_md5sha',\n",
       " 'extract_numbers',\n",
       " 'extract_pattern',\n",
       " 'extract_phone_numbers',\n",
       " 'extract_postoffice_box',\n",
       " 'extract_shortwords',\n",
       " 'extract_special_characters',\n",
       " 'extract_stopwords',\n",
       " 'extract_street_address',\n",
       " 'extract_terms_in_bracket',\n",
       " 'extract_urls',\n",
       " 'extract_userhandles',\n",
       " 'extract_visacard_addr',\n",
       " 'fix_contractions',\n",
       " 'generate_sentence',\n",
       " 'hamming_distance',\n",
       " 'inverse_df',\n",
       " 'lexical_richness',\n",
       " 'markov_chain',\n",
       " 'math',\n",
       " 'nlargest',\n",
       " 'normalize',\n",
       " 'num2words',\n",
       " 'random',\n",
       " 're',\n",
       " 'read_txt',\n",
       " 'remove_accents',\n",
       " 'remove_bad_quotes',\n",
       " 'remove_btc_address',\n",
       " 'remove_currencies',\n",
       " 'remove_currency_symbols',\n",
       " 'remove_custom_pattern',\n",
       " 'remove_custom_words',\n",
       " 'remove_dates',\n",
       " 'remove_emails',\n",
       " 'remove_emojis',\n",
       " 'remove_hashtags',\n",
       " 'remove_html_tags',\n",
       " 'remove_mastercard_addr',\n",
       " 'remove_md5sha',\n",
       " 'remove_multiple_spaces',\n",
       " 'remove_non_ascii',\n",
       " 'remove_numbers',\n",
       " 'remove_phone_numbers',\n",
       " 'remove_postoffice_box',\n",
       " 'remove_puncts',\n",
       " 'remove_punctuations',\n",
       " 'remove_shortwords',\n",
       " 'remove_special_characters',\n",
       " 'remove_stopwords',\n",
       " 'remove_street_address',\n",
       " 'remove_terms_in_bracket',\n",
       " 'remove_urls',\n",
       " 'remove_userhandles',\n",
       " 'remove_visacard_addr',\n",
       " 'replace_bad_quotes',\n",
       " 'replace_currencies',\n",
       " 'replace_currency_symbols',\n",
       " 'replace_dates',\n",
       " 'replace_emails',\n",
       " 'replace_emojis',\n",
       " 'replace_numbers',\n",
       " 'replace_phone_numbers',\n",
       " 'replace_special_characters',\n",
       " 'replace_term',\n",
       " 'replace_urls',\n",
       " 'string',\n",
       " 'term_freq',\n",
       " 'to_txt',\n",
       " 'unicodedata',\n",
       " 'word_freq',\n",
       " 'word_length_freq']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### html tags removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        []\n",
       "1        []\n",
       "2        []\n",
       "3        []\n",
       "4        []\n",
       "         ..\n",
       "81179    []\n",
       "81182    []\n",
       "81185    []\n",
       "81186    []\n",
       "81190    []\n",
       "Name: text, Length: 64860, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the texts from the dataframe containing html tags\n",
    "df['text'].apply(nfx.extract_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_html_tags function to each text in the DataFrame\n",
    "df['text'] = df['text'].apply(nfx.remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>.@mcdonalds said it would accept dogecoin if @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19163</th>\n",
       "      <td>.@Tesla Model X Plaid is ðŸ”¥ðŸš€\\n\\nHoping we see a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17525</th>\n",
       "      <td>.@adamhoov Bro, wake up! Our time has come! $T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17282</th>\n",
       "      <td>.@DivesTech is calling his shots:\\nðŸš— Tesla: â€œT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76705</th>\n",
       "      <td>.@Grayscale has launched its first exchange-tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "23220  .@mcdonalds said it would accept dogecoin if @...\n",
       "19163  .@Tesla Model X Plaid is ðŸ”¥ðŸš€\\n\\nHoping we see a...\n",
       "17525  .@adamhoov Bro, wake up! Our time has come! $T...\n",
       "17282  .@DivesTech is calling his shots:\\nðŸš— Tesla: â€œT...\n",
       "76705  .@Grayscale has launched its first exchange-tr..."
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # extracting all the texts from the dataframe containing emails\n",
    "# df[df[\"text\"].apply(nfx.extract_emails).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying the remove_html_tags function to each text in the DataFrame\n",
    "# df['text'] = df['text'].apply(nfx.remove_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing mobile numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extracting all the texts from the dataframe containing phone numbers\n",
    "# df[df[\"text\"].apply(nfx.extract_phone_numbers).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying the remove_phone_numbers function to each text in the DataFrame\n",
    "# df[\"text\"] = df[\"text\"].apply(nfx.remove_phone_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20219</th>\n",
       "      <td>We are living in 2022 and are seeing countries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18485</th>\n",
       "      <td>$TSLA will be the greatest investment story in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29371</th>\n",
       "      <td>You canâ€™t get rich in stock market if you canâ€™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31394</th>\n",
       "      <td>Giga Berlin starting operations will be by far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77887</th>\n",
       "      <td>An ES7 is now already on display at a new $NIO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "20219  We are living in 2022 and are seeing countries...\n",
       "18485  $TSLA will be the greatest investment story in...\n",
       "29371  You canâ€™t get rich in stock market if you canâ€™...\n",
       "31394  Giga Berlin starting operations will be by far...\n",
       "77887  An ES7 is now already on display at a new $NIO..."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the texts from the dataframe containing currency symbols\n",
    "df[df[\"text\"].apply(nfx.extract_currency_symbols).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_currency_symbols function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_currency_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>MI TOP5 PORTFOLIO LARGO PLAZO 15/08/2022\\n\\n1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>TSLA is currently ~737. I have a TSLA price pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37293</th>\n",
       "      <td>I predict 29,166 per TSLA share (if no additio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16749</th>\n",
       "      <td>Breaking - New TSLA price prediction of 25K/sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20875</th>\n",
       "      <td>TSLA Street FYâ€™22 EPS now 10.56, +21% since 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "3521   MI TOP5 PORTFOLIO LARGO PLAZO 15/08/2022\\n\\n1 ...\n",
       "7891   TSLA is currently ~737. I have a TSLA price pr...\n",
       "37293  I predict 29,166 per TSLA share (if no additio...\n",
       "16749  Breaking - New TSLA price prediction of 25K/sh...\n",
       "20875  TSLA Street FYâ€™22 EPS now 10.56, +21% since 12..."
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the texts from the dataframe containing dates\n",
    "df[df[\"text\"].apply(nfx.extract_dates).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_dates function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emojis removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27567</th>\n",
       "      <td>Wednesday Flow Setups ðŸŒŠ\\n\\nðŸš— TSLA 1000c\\nðŸ“± AAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56459</th>\n",
       "      <td>AAPL and QQQ calls going to print today...Ezpz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6900</th>\n",
       "      <td>Trading TSLA Live While Signaling To My Chat M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64604</th>\n",
       "      <td>ALGS Year2 Championship Day3\\nWinners Round 1è©¦...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33944</th>\n",
       "      <td>Fremont production is ripping.\\n\\nðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥\\n\\nTSLA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "27567  Wednesday Flow Setups ðŸŒŠ\\n\\nðŸš— TSLA 1000c\\nðŸ“± AAP...\n",
       "56459  AAPL and QQQ calls going to print today...Ezpz...\n",
       "6900   Trading TSLA Live While Signaling To My Chat M...\n",
       "64604  ALGS Year2 Championship Day3\\nWinners Round 1è©¦...\n",
       "33944  Fremont production is ripping.\\n\\nðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥\\n\\nTSLA..."
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the texts from the dataframe containing emojis\n",
    "df[df[\"text\"].apply(nfx.extract_emojis).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_emojis function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing userhandles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27562</th>\n",
       "      <td>The @Tesla is pure joy on wheels. Thankful for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23034</th>\n",
       "      <td>TSLA reports nearly 60,000 cars now with #Auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22355</th>\n",
       "      <td>Yesterday i took delivery of my @Tesla model x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17148</th>\n",
       "      <td>@elonmusk @Tesla @WholeMarsBlog Not to brag, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>\"The President strongly believes in every work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "27562  The @Tesla is pure joy on wheels. Thankful for...\n",
       "23034  TSLA reports nearly 60,000 cars now with #Auto...\n",
       "22355  Yesterday i took delivery of my @Tesla model x...\n",
       "17148  @elonmusk @Tesla @WholeMarsBlog Not to brag, b...\n",
       "21460  \"The President strongly believes in every work..."
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the texts from the dataframe containing userhandles\n",
    "df[df[\"text\"].apply(nfx.extract_userhandles).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_userhandles function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>https://t.co/EYyYHFx5LK - Teslaâ€™s Autopilot Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62460</th>\n",
       "      <td>#Netflix \\n\\nNFLX https://t.co/fBQSRENciI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15964</th>\n",
       "      <td>Teslaâ€™s Texas Gigafactory puts the nail in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24607</th>\n",
       "      <td>True financial freedom is having zero financia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19747</th>\n",
       "      <td>Jimmy said he wants me to buy whatever  I want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "2896   https://t.co/EYyYHFx5LK - Teslaâ€™s Autopilot Le...\n",
       "62460          #Netflix \\n\\nNFLX https://t.co/fBQSRENciI\n",
       "15964  Teslaâ€™s Texas Gigafactory puts the nail in the...\n",
       "24607  True financial freedom is having zero financia...\n",
       "19747  Jimmy said he wants me to buy whatever  I want..."
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the texts from the dataframe containing hashtags\n",
    "df[df[\"text\"].apply(nfx.extract_hashtags).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_hashtags function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9154</th>\n",
       "      <td>Carcissism (noun): excessive interest in or ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64867</th>\n",
       "      <td>The push for top four is getting tight, we are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64770</th>\n",
       "      <td>Great teamplay we win in a 7-1 fashion against...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38760</th>\n",
       "      <td>The biggest moat, i am going to, in AMZN retai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10844</th>\n",
       "      <td>TSLA TSLAQ\\n\\nFound this posted in Tesla Share...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "9154   Carcissism (noun): excessive interest in or ad...\n",
       "64867  The push for top four is getting tight, we are...\n",
       "64770  Great teamplay we win in a 7-1 fashion against...\n",
       "38760  The biggest moat, i am going to, in AMZN retai...\n",
       "10844  TSLA TSLAQ\\n\\nFound this posted in Tesla Share..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the texts from the dataframe containing special characters\n",
    "df[df[\"text\"].apply(nfx.extract_special_characters).apply(lambda x: len(x) > 0) == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_special_characters function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing multiple spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_multiple_spaces function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_multiple_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### urls removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_urls function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81179</th>\n",
       "      <td>crucial zone for either side httpstcohia7jvo5pw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81182</th>\n",
       "      <td>some of my picks blasted during this wishing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81185</th>\n",
       "      <td>sbi buy is possible tradingview httpstcocdsch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81186</th>\n",
       "      <td>very important document cheque book tracking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81190</th>\n",
       "      <td>muharat pick 6buy sbi at current market price ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "81179    crucial zone for either side httpstcohia7jvo5pw\n",
       "81182  some of my picks blasted during this wishing a...\n",
       "81185   sbi buy is possible tradingview httpstcocdsch...\n",
       "81186   very important document cheque book tracking ...\n",
       "81190  muharat pick 6buy sbi at current market price ..."
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the lower function to each text in the DataFrame\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25598</th>\n",
       "      <td>as the price of pltr drops i could not be more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>tsla slipping already in pm gives me a chance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39041</th>\n",
       "      <td>breaking amazon amzn downgraded from sell to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65746</th>\n",
       "      <td>another flawless for httpstcofhnjse12ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>every morning i tweet out my spy spx tsla leve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "25598  as the price of pltr drops i could not be more...\n",
       "18213  tsla slipping already in pm gives me a chance ...\n",
       "39041  breaking amazon amzn downgraded from sell to c...\n",
       "65746            another flawless for httpstcofhnjse12ca\n",
       "1700   every morning i tweet out my spy spx tsla leve..."
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the remove_punctuations function to each text in the DataFrame\n",
    "df[\"text\"] = df[\"text\"].apply(nfx.remove_punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mainstream media has done an amazing job at b...</td>\n",
       "      <td>[mainstream, media, has, done, an, amazing, jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tesla delivery estimates are at around 364k fr...</td>\n",
       "      <td>[tesla, delivery, estimates, are, at, around, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 even if i include 630m unvested rsus as of 6...</td>\n",
       "      <td>[3, even, if, i, include, 630m, unvested, rsus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hahaha why are you still trying to stop tesla...</td>\n",
       "      <td>[hahaha, why, are, you, still, trying, to, sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop trying to kill kids you sad deranged old...</td>\n",
       "      <td>[stop, trying, to, kill, kids, you, sad, deran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   mainstream media has done an amazing job at b...   \n",
       "1  tesla delivery estimates are at around 364k fr...   \n",
       "2  3 even if i include 630m unvested rsus as of 6...   \n",
       "3   hahaha why are you still trying to stop tesla...   \n",
       "4   stop trying to kill kids you sad deranged old...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [mainstream, media, has, done, an, amazing, jo...  \n",
       "1  [tesla, delivery, estimates, are, at, around, ...  \n",
       "2  [3, even, if, i, include, 630m, unvested, rsus...  \n",
       "3  [hahaha, why, are, you, still, trying, to, sto...  \n",
       "4  [stop, trying, to, kill, kids, you, sad, deran...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to remove stop words from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "\n",
    "# Applying the remove_stopwords function\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mainstream media has done an amazing job at b...</td>\n",
       "      <td>[mainstream, media, done, amazing, job, brainw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tesla delivery estimates are at around 364k fr...</td>\n",
       "      <td>[tesla, delivery, estimates, around, 364k, ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 even if i include 630m unvested rsus as of 6...</td>\n",
       "      <td>[3, even, include, 630m, unvested, rsus, 630, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hahaha why are you still trying to stop tesla...</td>\n",
       "      <td>[hahaha, still, trying, stop, tesla, fsd, bro,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop trying to kill kids you sad deranged old...</td>\n",
       "      <td>[stop, trying, kill, kids, sad, deranged, old,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   mainstream media has done an amazing job at b...   \n",
       "1  tesla delivery estimates are at around 364k fr...   \n",
       "2  3 even if i include 630m unvested rsus as of 6...   \n",
       "3   hahaha why are you still trying to stop tesla...   \n",
       "4   stop trying to kill kids you sad deranged old...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [mainstream, media, done, amazing, job, brainw...  \n",
       "1  [tesla, delivery, estimates, around, 364k, ana...  \n",
       "2  [3, even, include, 630m, unvested, rsus, 630, ...  \n",
       "3  [hahaha, still, trying, stop, tesla, fsd, bro,...  \n",
       "4  [stop, trying, kill, kids, sad, deranged, old,...  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    # joining the tokens into a space-separated string\n",
    "    text = \" \".join(tokens)\n",
    "    # processing the text using spaCy with nlp\n",
    "    doc = nlp(text)\n",
    "    # extracting lemmas from spaCy's document object\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    return lemmas\n",
    "\n",
    "# Applying the lemmatize_tokens function\n",
    "df[\"lemmatized\"] = df[\"tokens\"].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mainstream media has done an amazing job at b...</td>\n",
       "      <td>[mainstream, media, done, amazing, job, brainw...</td>\n",
       "      <td>[mainstream, medium, do, amazing, job, brainwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tesla delivery estimates are at around 364k fr...</td>\n",
       "      <td>[tesla, delivery, estimates, around, 364k, ana...</td>\n",
       "      <td>[tesla, delivery, estimate, around, 364k, anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 even if i include 630m unvested rsus as of 6...</td>\n",
       "      <td>[3, even, include, 630m, unvested, rsus, 630, ...</td>\n",
       "      <td>[3, even, include, 630, m, unvested, rsus, 630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hahaha why are you still trying to stop tesla...</td>\n",
       "      <td>[hahaha, still, trying, stop, tesla, fsd, bro,...</td>\n",
       "      <td>[hahaha, still, try, stop, tesla, fsd, bro, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop trying to kill kids you sad deranged old...</td>\n",
       "      <td>[stop, trying, kill, kids, sad, deranged, old,...</td>\n",
       "      <td>[stop, try, kill, kid, sad, derange, old, man]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   mainstream media has done an amazing job at b...   \n",
       "1  tesla delivery estimates are at around 364k fr...   \n",
       "2  3 even if i include 630m unvested rsus as of 6...   \n",
       "3   hahaha why are you still trying to stop tesla...   \n",
       "4   stop trying to kill kids you sad deranged old...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [mainstream, media, done, amazing, job, brainw...   \n",
       "1  [tesla, delivery, estimates, around, 364k, ana...   \n",
       "2  [3, even, include, 630m, unvested, rsus, 630, ...   \n",
       "3  [hahaha, still, trying, stop, tesla, fsd, bro,...   \n",
       "4  [stop, trying, kill, kids, sad, deranged, old,...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [mainstream, medium, do, amazing, job, brainwa...  \n",
       "1  [tesla, delivery, estimate, around, 364k, anal...  \n",
       "2  [3, even, include, 630, m, unvested, rsus, 630...  \n",
       "3  [hahaha, still, try, stop, tesla, fsd, bro, ge...  \n",
       "4     [stop, try, kill, kid, sad, derange, old, man]  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['lemmatized'].apply(lambda token:' '.join(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        mainstream medium do amazing job brainwash peo...\n",
       "1         tesla delivery estimate around 364k analyst tsla\n",
       "2        3 even include 630 m unvested rsus 630 additio...\n",
       "3        hahaha still try stop tesla fsd bro get shit t...\n",
       "4                    stop try kill kid sad derange old man\n",
       "                               ...                        \n",
       "81179          crucial zone either side httpstcohia7jvo5pw\n",
       "81182                              pick blast wish success\n",
       "81185     sbi buy possible tradingview httpstcocdschfjg2 m\n",
       "81186    important document cheque book track numberjb2...\n",
       "81190    muharat pick 6buy sbi current market price til...\n",
       "Name: cleaned_text, Length: 64860, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"text_dataset_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
